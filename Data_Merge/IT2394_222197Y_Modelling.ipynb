{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import re\n",
    "from dateutil import parser\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from wordcloud import STOPWORDS\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>['lately', 'common', 'wait', 'hour', 'food', '...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>['love', 'great', 'offer', 'good', 'selection'...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>['disappointed', 'app', 'used', 'long', 'time'...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>['fairly', 'easy', 'use', 'trying', 'find', 'h...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>['like', 'fact', 'u', 'ca', 'get', 'refund', '...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8892</th>\n",
       "      <td>5</td>\n",
       "      <td>['food', 'good', 'delivery', 'took', 'forever'...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8893</th>\n",
       "      <td>1</td>\n",
       "      <td>['whenever', 'never', 'sent', 'correct', 'item...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8894</th>\n",
       "      <td>1</td>\n",
       "      <td>['delivery', 'driver', 'turn', 'incorrect', 'l...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8895</th>\n",
       "      <td>5</td>\n",
       "      <td>['great', 'deal', 'buddy', 'pizza', 'buy', 'on...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8896</th>\n",
       "      <td>5</td>\n",
       "      <td>['prompt', 'service', 'excellent', 'communicat...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8897 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      stars                                       cleaned_text sentiment\n",
       "0         1  ['lately', 'common', 'wait', 'hour', 'food', '...  negative\n",
       "1         5  ['love', 'great', 'offer', 'good', 'selection'...  positive\n",
       "2         1  ['disappointed', 'app', 'used', 'long', 'time'...  negative\n",
       "3         2  ['fairly', 'easy', 'use', 'trying', 'find', 'h...  negative\n",
       "4         4  ['like', 'fact', 'u', 'ca', 'get', 'refund', '...  positive\n",
       "...     ...                                                ...       ...\n",
       "8892      5  ['food', 'good', 'delivery', 'took', 'forever'...  positive\n",
       "8893      1  ['whenever', 'never', 'sent', 'correct', 'item...  negative\n",
       "8894      1  ['delivery', 'driver', 'turn', 'incorrect', 'l...  negative\n",
       "8895      5  ['great', 'deal', 'buddy', 'pizza', 'buy', 'on...  positive\n",
       "8896      5  ['prompt', 'service', 'excellent', 'communicat...  positive\n",
       "\n",
       "[8897 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cleaned_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count the number of each sentiment\n",
    "sentiment_counts = df['sentiment'].value_counts()\n",
    "\n",
    "# Plot bar chart\n",
    "sentiment_counts.plot(kind='bar', figsize=(10,7))\n",
    "\n",
    "plt.title('Count of Sentiments')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "#  convert string representations of lists in 'cleaned_text' back to actual lists\n",
    "df['cleaned_text_list'] = df['cleaned_text'].apply(ast.literal_eval)\n",
    "\n",
    "# convert lists in 'cleaned_text_list' to strings\n",
    "df['cleaned_text_str'] = df['cleaned_text_list'].apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert 'cleaned_text_str' into TF-IDF vectors\n",
    "X = vectorizer.fit_transform(df['cleaned_text_str'])\n",
    "\n",
    "# use 'sentiment' as target\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define oversampling strategy\n",
    "over = RandomOverSampler(sampling_strategy='auto')\n",
    "\n",
    "# Fit and apply the transform\n",
    "X_over, y_over = over.fit_resample(X, y)\n",
    "\n",
    "# Define undersampling strategy\n",
    "under = RandomUnderSampler(sampling_strategy='auto')\n",
    "\n",
    "# Fit and apply the transform\n",
    "X_under, y_under = under.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Fit and apply the transform\n",
    "X_under, y_under = under.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Metrics for Oversampled Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.90      0.93      1209\n",
      "     neutral       0.92      0.99      0.96      1238\n",
      "    positive       0.95      0.93      0.94      1194\n",
      "\n",
      "    accuracy                           0.94      3641\n",
      "   macro avg       0.94      0.94      0.94      3641\n",
      "weighted avg       0.94      0.94      0.94      3641\n",
      "\n",
      "\n",
      "Accuracy:  0.9412249382037902\n",
      "\n",
      "Precision:  0.9421538909162167\n",
      "\n",
      "Recall:  0.9412249382037902\n",
      "\n",
      "F1 Score:  0.9408919518832837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# split the oversampled data into training and test sets\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over, test_size=0.2, random_state=42)\n",
    "\n",
    "# initialize and train the Logistic Regression model on the oversampled data\n",
    "lr_model_over = LogisticRegression()\n",
    "lr_model_over.fit(X_train_over, y_train_over)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred_over = lr_model_over.predict(X_test_over)\n",
    "\n",
    "# print classification report for the oversampled data\n",
    "print(\"Logistic Regression Metrics for Oversampled Data:\")\n",
    "print(classification_report(y_test_over, y_pred_over))\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# print accuracy\n",
    "print(\"\\nAccuracy: \", accuracy_score(y_test_over, y_pred_over))\n",
    "\n",
    "# print precision\n",
    "print(\"\\nPrecision: \", precision_score(y_test_over, y_pred_over, average='weighted'))\n",
    "\n",
    "# print recall\n",
    "print(\"\\nRecall: \", recall_score(y_test_over, y_pred_over, average='weighted'))\n",
    "\n",
    "# print F1 score\n",
    "print(\"\\nF1 Score: \", f1_score(y_test_over, y_pred_over, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Metrics for Undersampled Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.75      0.74        84\n",
      "     neutral       0.57      0.61      0.59        77\n",
      "    positive       0.74      0.66      0.70        73\n",
      "\n",
      "    accuracy                           0.68       234\n",
      "   macro avg       0.68      0.67      0.67       234\n",
      "weighted avg       0.68      0.68      0.68       234\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# split the undersampled data into training and test sets\n",
    "X_train_under, X_test_under, y_train_under, y_test_under = train_test_split(X_under, y_under, test_size=0.2, random_state=42)\n",
    "\n",
    "# initialize and train the Logistic Regression model on the undersampled data\n",
    "lr_model_under = LogisticRegression()\n",
    "lr_model_under.fit(X_train_under, y_train_under)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred_under = lr_model_under.predict(X_test_under)\n",
    "\n",
    "# print classification report for the undersampled data\n",
    "print(\"\\nLogistic Regression Metrics for Undersampled Data:\")\n",
    "print(classification_report(y_test_under, y_pred_under))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy:  0.6752136752136753\n",
      "\n",
      "Precision:  0.6796794259281059\n",
      "\n",
      "Recall:  0.6752136752136753\n",
      "\n",
      "F1 Score:  0.6764056932695041\n"
     ]
    }
   ],
   "source": [
    "# make predictions on the test set for undersampled data\n",
    "y_pred_under = lr_model_under.predict(X_test_under)\n",
    "\n",
    "# print accuracy\n",
    "print(\"\\nAccuracy: \", accuracy_score(y_test_under, y_pred_under))\n",
    "\n",
    "# print precision\n",
    "print(\"\\nPrecision: \", precision_score(y_test_under, y_pred_under, average='weighted'))\n",
    "\n",
    "# print recall\n",
    "print(\"\\nRecall: \", recall_score(y_test_under, y_pred_under, average='weighted'))\n",
    "\n",
    "# print F1 score\n",
    "print(\"\\nF1 Score: \", f1_score(y_test_under, y_pred_under, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some reasons why the above has happend\n",
    "\n",
    "Loss of Information: When you undersample, you're essentially discarding potentially useful information. The randomly removed instances from the majority class could contain important information that the model needs to correctly classify new instances.\n",
    "\n",
    "Overfitting: If the minority class is very small compared to the majority class, undersampling can lead to overfitting. The model trained on the undersampled dataset might not generalize well to new, unseen data.\n",
    "\n",
    "Representation: The undersampled dataset may not adequately represent the majority class, especially if the class is not homogeneous. This can lead to a model that performs poorly on the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90      1229\n",
      "     neutral       0.00      0.00      0.00        80\n",
      "    positive       0.96      0.59      0.73       471\n",
      "\n",
      "    accuracy                           0.84      1780\n",
      "   macro avg       0.59      0.53      0.54      1780\n",
      "weighted avg       0.82      0.84      0.81      1780\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# initialize and train the Naive Bayes model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# print classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy:  0.8438202247191011\n",
      "\n",
      "Precision:  0.8203547354525488\n",
      "\n",
      "Recall:  0.8438202247191011\n",
      "\n",
      "F1 Score:  0.8149343812490736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# print accuracy\n",
    "print(\"\\nAccuracy: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# print precision\n",
    "print(\"\\nPrecision: \", precision_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "# print recall\n",
    "print(\"\\nRecall: \", recall_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "# print F1 score\n",
    "print(\"\\nF1 Score: \", f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94      1229\n",
      "     neutral       0.44      0.05      0.09        80\n",
      "    positive       0.85      0.88      0.86       471\n",
      "\n",
      "    accuracy                           0.90      1780\n",
      "   macro avg       0.74      0.63      0.63      1780\n",
      "weighted avg       0.88      0.90      0.88      1780\n",
      "\n",
      "\n",
      "Accuracy:  0.897191011235955\n",
      "\n",
      "Precision:  0.8790535623987709\n",
      "\n",
      "Recall:  0.897191011235955\n",
      "\n",
      "F1 Score:  0.8806843565173719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# initialize and train the SVM model\n",
    "svm_model = LinearSVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "svm_y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# print classification report for SVM\n",
    "print(\"\\nSVM Metrics:\")\n",
    "print(classification_report(y_test, svm_y_pred))\n",
    "\n",
    "# print accuracy\n",
    "print(\"\\nAccuracy: \", accuracy_score(y_test, svm_y_pred))\n",
    "\n",
    "# print precision\n",
    "print(\"\\nPrecision: \", precision_score(y_test, svm_y_pred, average='weighted'))\n",
    "\n",
    "# print recall\n",
    "print(\"\\nRecall: \", recall_score(y_test, svm_y_pred, average='weighted'))\n",
    "\n",
    "# print F1 score\n",
    "print(\"\\nF1 Score: \", f1_score(y_test, svm_y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# initialize and train the Logistic Regression model\u001b[39;00m\n\u001b[0;32m      5\u001b[0m lr_model \u001b[38;5;241m=\u001b[39m LogisticRegression()\n\u001b[1;32m----> 6\u001b[0m \u001b[43mlr_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# make predictions on the test set\u001b[39;00m\n\u001b[0;32m      9\u001b[0m lr_y_pred \u001b[38;5;241m=\u001b[39m lr_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:1303\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1300\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1301\u001b[0m     n_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1303\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1306\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1313\u001b[0m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1326\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1328\u001b[0m fold_coefs_, _, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_iter_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:452\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[0;32m    448\u001b[0m l2_reg_strength \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m C\n\u001b[0;32m    449\u001b[0m iprint \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m101\u001b[39m][\n\u001b[0;32m    450\u001b[0m     np\u001b[38;5;241m.\u001b[39msearchsorted(np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]), verbose)\n\u001b[0;32m    451\u001b[0m ]\n\u001b[1;32m--> 452\u001b[0m opt_res \u001b[38;5;241m=\u001b[39m \u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_reg_strength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43miprint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43miprint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgtol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxiter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    460\u001b[0m n_iter_i \u001b[38;5;241m=\u001b[39m _check_optimize_result(\n\u001b[0;32m    461\u001b[0m     solver,\n\u001b[0;32m    462\u001b[0m     opt_res,\n\u001b[0;32m    463\u001b[0m     max_iter,\n\u001b[0;32m    464\u001b[0m     extra_warning_msg\u001b[38;5;241m=\u001b[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[0;32m    465\u001b[0m )\n\u001b[0;32m    466\u001b[0m w0, loss \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\optimize\\_minimize.py:710\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    707\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    708\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 710\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    713\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    714\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:365\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    359\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[0;32m    364\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[1;32m--> 365\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[0;32m    368\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\optimize\\_differentiable_functions.py:283\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfun_and_grad\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m--> 283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_equal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    284\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\core\\numeric.py:2439\u001b[0m, in \u001b[0;36marray_equal\u001b[1;34m(a1, a2, equal_nan)\u001b[0m\n\u001b[0;32m   2437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   2438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m equal_nan:\n\u001b[1;32m-> 2439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(asarray(a1 \u001b[38;5;241m==\u001b[39m a2)\u001b[38;5;241m.\u001b[39mall())\n\u001b[0;32m   2440\u001b[0m \u001b[38;5;66;03m# Handling NaN values if equal_nan is True\u001b[39;00m\n\u001b[0;32m   2441\u001b[0m a1nan, a2nan \u001b[38;5;241m=\u001b[39m isnan(a1), isnan(a2)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# initialize and train the Logistic Regression model\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "lr_y_pred = lr_model.predict(X_test)\n",
    "\n",
    "# print classification report for Logistic Regression\n",
    "print(\"Logistic Regression Metrics:\")\n",
    "print(classification_report(y_test, lr_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy:  0.9039325842696629\n",
      "\n",
      "Precision:  0.8638003662216415\n",
      "\n",
      "Recall:  0.9039325842696629\n",
      "\n",
      "F1 Score:  0.8832492999681\n"
     ]
    }
   ],
   "source": [
    "# print accuracy\n",
    "print(\"\\nAccuracy: \", accuracy_score(y_test, lr_y_pred))\n",
    "\n",
    "# print precision\n",
    "print(\"\\nPrecision: \", precision_score(y_test, lr_y_pred, average='weighted'))\n",
    "\n",
    "# print recall\n",
    "print(\"\\nRecall: \", recall_score(y_test, lr_y_pred, average='weighted'))\n",
    "\n",
    "# print F1 score\n",
    "print(\"\\nF1 Score: \", f1_score(y_test, lr_y_pred, average='weighted'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
