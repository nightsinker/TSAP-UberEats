{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import requests \n",
    "import pandas as pd \n",
    "import time\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.keys import Keys \n",
    "from selenium.webdriver.chrome.service import Service \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.hellopeter.com/uber-eats?page='  \n",
    "# urls = [url + str(page) for page in range(1, 4)]\n",
    "# print(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\"><head><meta charset=\"utf-8\"/><meta content=\"width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no\" name=\"viewport\"/><title>Review Companies Online | Customer Service &amp; Company Ratings | hellopeter.com</title><meta content=\"https://www.hellopeter.com/static/img/logo/hp-fb-crawl-3.png\" property=\"og:image\"/><link href=\"/static/img/logo/favicon-180x180.png?1\" rel=\"apple-touch-icon\" sizes=\"180x180\"/><link href=\"/static/img/logo/favicon-32x32.png?1\" rel=\"icon\" sizes=\"32x32\" type=\"image/png\"/><link href=\"/static/img/logo/favicon-16x16.png?1\" rel=\"icon\" sizes=\"16x16\" type=\"image/png\"/><link color=\"#25a8e2\" href=\"/static/img/safari-pinned-tab.svg\" rel=\"mask-icon\"/><link crossorigin=\"anonymous\" href=\"https://use.fontawesome.com/releases/v5.5.0/css/all.css\" integrity=\"sha384-B4dIYHKNBt8Bc12p+WXckhzcICo0wtJAoU8YZTY5qE0Id1GSseTk6S+L3BlXeVIU\" rel=\"stylesheet\"/><link href=\"https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i,800,800i\" rel=\"stylesheet\"/><link href=\"https://fonts.googleapis.com/css?family=Montserrat:black,blackitalic,bold,bolditalic,extrabold,extrabolditalic,italic,light,lightitalic,medium,mediumitalic,regular,semibold,semibolditalic,thin,thinitalic\" rel=\"stylesheet\"/><link href=\"https://fonts.googleapis.com\" rel=\"preconnect\"/><link crossorigin=\"\" href=\"https://fonts.gstatic.com\" rel=\"preconnect\"/><link href=\"https://fonts.googleapis.com/css2?family=Roboto&amp;display=swap\" rel=\"stylesheet\"/><link href=\"https://fonts.googleapis.com/css2?family=Mulish:wght@700&amp;family=Roboto&amp;display=swap\" rel=\"stylesheet\"/><script src=\"https://maps.googleapis.com/maps/api/js?key=AIzaSyATQx52byjPXOYEjq0U8tOrJAO6a-H1lKs&amp;libraries=places\"></script><script async=\"async\" src=\"https://securepubads.g.doubleclick.net/tag/js/gpt.js\"></script><script>window.googletag = window.googletag || {cmd: []};\n",
      "        window.isMobile = false;</script><link href=\"/static/css/app.103309340850c62fa8ced73322b787b6.css\" rel=\"stylesheet\"/></head><body><script>window.prerenderReady = false;</script><div id=\"app\"></div><script id=\"facebook-jssdk\" src=\"https://connect.facebook.net/en_US/sdk.js\"></script><script src=\"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js\"></script><script async=\"\" src=\"m2d.m2.ai/pg.hellopeter.com.js\"></script><script async=\"\" src=\"cdn.pubguru.com/fb.js\"></script><script src=\"/static/js/manifest.2ae2e69a05c33dfc65f8.js\" type=\"text/javascript\"></script><script src=\"/static/js/vendor.8f44381caf77f4b76117.js\" type=\"text/javascript\"></script><script src=\"/static/js/app.67f722e0349fae8a4900.js\" type=\"text/javascript\"></script></body></html>\n"
     ]
    }
   ],
   "source": [
    "resp = requests.get(url)\n",
    "content = BeautifulSoup(resp.content, 'lxml')\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_reviews(url):\n",
    "\n",
    "  service = Service(executable_path=\"C:\\\\Program Files (x86)\\\\chromedriver.exe\")\n",
    "  driver = webdriver.Chrome(service=service)\n",
    "  reviews = []\n",
    "\n",
    "  driver.get(url)\n",
    "    \n",
    "  cards = driver.find_elements(By.CSS_SELECTOR, '.review-card')\n",
    "\n",
    "  for card in cards:\n",
    "  \n",
    "    try:\n",
    "      name = card.find_element(By.CSS_SELECTOR, '.has-text-weight-bold').text\n",
    "\n",
    "      # Find date element using BeautifulSoup for more flexibility\n",
    "      date_element = card.find_element(By.XPATH, \".//div[contains(text(), 'at')]\")\n",
    "      date_text = date_element.text\n",
    "\n",
    "      # Extract date using BeautifulSoup and regex\n",
    "      soup = BeautifulSoup(date_text, 'html.parser')\n",
    "      date_match = re.search(r'(\\d+ \\w+ \\d+ at \\d+:\\d+)', soup.get_text())\n",
    "      date = date_match.group(1) if date_match else None\n",
    "      \n",
    "      rating = len(card.find_elements(By.CSS_SELECTOR, '.is-star-1'))\n",
    "      \n",
    "      title = card.find_element(By.CSS_SELECTOR, '.has-text-weight-bold.margin-top-24').text\n",
    "      \n",
    "      review = card.find_element(By.CSS_SELECTOR, '.margin-bottom-15').text\n",
    "      \n",
    "      review_data = {\n",
    "        'review': review,\n",
    "        'date': date, \n",
    "        'stars': rating,\n",
    "        'name': name,\n",
    "        'source': 'hellopeter',\n",
    "        'title': title\n",
    "      }\n",
    "\n",
    "      reviews.append(review_data)\n",
    "      \n",
    "    except Exception as e:\n",
    "      print(e)\n",
    "      continue\n",
    "\n",
    "\n",
    "  driver.quit()\n",
    "\n",
    "  return pd.DataFrame(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def scrape_reviews(url):\n",
    "  service = Service(executable_path=\"C:\\\\Program Files (x86)\\\\chromedriver.exe\")\n",
    "\n",
    "  driver = webdriver.Chrome(service=service)\n",
    "\n",
    "  reviews = []\n",
    "\n",
    "  driver.get(url)\n",
    "\n",
    "  num_pages = 5\n",
    "\n",
    "  for i in range(num_pages):\n",
    "\n",
    "    # Wait for reviews to load\n",
    "    time.sleep(5)\n",
    "\n",
    "    cards = driver.find_elements(By.CSS_SELECTOR, '.review-card')\n",
    "\n",
    "    for card in cards:\n",
    "\n",
    "      try:\n",
    "        name = card.find_element(By.CSS_SELECTOR, '.reviewer-name').text\n",
    "\n",
    "        date_element = card.find_element(By.XPATH, \".//div[contains(text(), 'on')]\")\n",
    "        date_text = date_element.text\n",
    "\n",
    "        soup = BeautifulSoup(date_text, 'html.parser')\n",
    "        date = soup.select_one('div:nth-of-type(1)').text\n",
    "\n",
    "        rating = len(card.find_elements(By.CSS_SELECTOR, '.fa-star.checked'))\n",
    "\n",
    "        title = card.find_element(By.CSS_SELECTOR, '.review-title').text\n",
    "        \n",
    "        review = card.find_element(By.CSS_SELECTOR, '.review-content').text\n",
    "\n",
    "        review_data = {\n",
    "          'name': name,\n",
    "          'date': date,\n",
    "          'rating': rating,\n",
    "          'title': title,\n",
    "          'review': review\n",
    "        }\n",
    "\n",
    "        reviews.append(review_data)\n",
    "\n",
    "      except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "    # Click next button\n",
    "    try:\n",
    "      next_button = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.CSS_SELECTOR, \".next-page\"))\n",
    "      )\n",
    "      next_button.click() \n",
    "\n",
    "    except:\n",
    "      print(\"No more pages\")\n",
    "      break\n",
    "      \n",
    "    time.sleep(5)\n",
    "      \n",
    "  driver.quit()\n",
    "\n",
    "  return pd.DataFrame(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_reviews(start_url, num_pages=5):\n",
    "    service = Service(executable_path=\"C:\\\\Program Files (x86)\\\\chromedriver.exe\")\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "    item_list = []\n",
    "\n",
    "    current_page = 1\n",
    "    while current_page <= num_pages:\n",
    "        driver.get(start_url)\n",
    "        content = driver.find_elements(By.CLASS_NAME, 'hp-card.review-card')\n",
    "\n",
    "        for post in content:\n",
    "            try:\n",
    "                name = post.find_element(By.CLASS_NAME, 'font-size-16').text\n",
    "                \n",
    "                date_element = post.find_element(By.XPATH, \".//div[contains(text(), 'on')]\")\n",
    "                date_text = date_element.text\n",
    "\n",
    "                soup = BeautifulSoup(date_text, 'html.parser')\n",
    "                date = soup.select_one('div:nth-of-type(1)').text\n",
    "\n",
    "                date = ' '.join(date)\n",
    "                stars = post.find_element(By.CLASS_NAME, 'is-star-1').text.count('1')\n",
    "                review = post.find_element(By.CLASS_NAME, 'margin-bottom-15').text\n",
    "\n",
    "                data = {\n",
    "                    'name': name,\n",
    "                    'date': date,\n",
    "                    'stars': stars,\n",
    "                    'review': review,\n",
    "                    'source': 'hellopeter',\n",
    "                }\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "                continue\n",
    "\n",
    "            item_list.append(data)\n",
    "\n",
    "        try:\n",
    "            # Scroll down to load more reviews\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(2)  # Add a delay to allow the page to load after scrolling\n",
    "\n",
    "            # Find and click the \"Next\" button with waiting\n",
    "            next_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, 'pagination-next'))\n",
    "            )\n",
    "            next_button.click()\n",
    "            current_page += 1\n",
    "\n",
    "            # Add a delay to allow the page to load before scraping\n",
    "            time.sleep(2)\n",
    "        except Exception as e:\n",
    "            print(f\"Error clicking 'Next' button: {e}\")\n",
    "            break  # Break the loop if there is an issue clicking the next button\n",
    "\n",
    "    driver.quit()\n",
    "    return pd.DataFrame(item_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 'NoneType' object has no attribute 'text'\n",
      "Error: 'NoneType' object has no attribute 'text'\n",
      "Error: 'NoneType' object has no attribute 'text'\n",
      "Error: 'NoneType' object has no attribute 'text'\n",
      "Error: 'NoneType' object has no attribute 'text'\n",
      "Error: 'NoneType' object has no attribute 'text'\n",
      "Error: 'NoneType' object has no attribute 'text'\n",
      "Error: 'NoneType' object has no attribute 'text'\n",
      "Error: 'NoneType' object has no attribute 'text'\n",
      "Error: 'NoneType' object has no attribute 'text'\n",
      "Error: 'NoneType' object has no attribute 'text'\n",
      "Error clicking 'Next' button: Message: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews = scrape_reviews(url, num_pages=5)\n",
    "df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews.to_csv(\"ubereats_hellopeter.csv\", index= False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
